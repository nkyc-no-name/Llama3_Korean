{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkyc-no-name/Llama3_Korean/blob/main/whisper_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!chmod 777 /home/hosungnam/ffmpeg/*\n",
        "\n",
        "import os\n",
        "# os.environ[\"PATH\"] += ':/ffmpeg'\n",
        "os.environ[\"PATH\"] += ':/home/hosungnam/ffmpeg'\n"
      ],
      "metadata": {
        "id": "z2OVcdRXYXgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -U gradio\n",
        "# !pip install gradio==3.50.2\n",
        "import gradio as gr\n",
        "import whisper\n",
        "\n",
        "paramfp16=False # Set to True if you want to use fp16 precision on GPU\n",
        "def transcribe(audio):\n",
        "    model = whisper.load_model(\"large-v3\")\n",
        "    result = model.transcribe(audio,fp16=paramfp16)\n",
        "    print(result[\"text\"])\n",
        "    return result[\"text\"]\n",
        "\n",
        "paramfp16=False # Set to True if you want to use fp16 precision on GPU\n",
        "\n",
        "def processAudio(audio1,audio2,choiceTranslate):\n",
        "    model = whisper.load_model(\"large-v3\")\n",
        "\n",
        "    if audio1 is None and audio2 is None:\n",
        "        return \"No audio inputs were provided.\"\n",
        "    elif audio1 is None:\n",
        "        # Process only the second audio input\n",
        "        # Your audio processing code here\n",
        "        # For this example, we'll just return the second audio input\n",
        "        audioOk = audio2\n",
        "    elif audio2 is None:\n",
        "        # Process only the first audio input\n",
        "        # Your audio processing code here\n",
        "        # For this example, we'll just return the first audio input\n",
        "        audioOk = audio1\n",
        "    else:\n",
        "        audioOk = audio1\n",
        "    result = model.transcribe(audioOk,fp16=paramfp16)\n",
        "    print(result[\"text\"])\n",
        "    return result[\"text\"]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    processAudio,\n",
        "    [\n",
        "        gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Record Audio\", show_label=True, optional=True),\n",
        "        gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload Audio\", show_label=True, optional=True)\n",
        "    ],\n",
        "    \"textbox\",\n",
        "    title=\"Demo App 0: Whisper model in offline mode\",\n",
        "    description=\"Record your speech via microphone or upload an audio file and press the Submit button to transcribe it into text. Please, note that the size of the audio file should be less than 25 MB.\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "g8WzE13EO4ed",
        "outputId": "27ebb905-cb7a-41a3-c482-4a356ac20c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_747735/3867087119.py:39: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  gr.Audio(source=\"microphone\", type=\"filepath\", label=\"Record Audio\", show_label=True, optional=True),\n",
            "/tmp/ipykernel_747735/3867087119.py:40: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  gr.Audio(source=\"upload\", type=\"filepath\", label=\"Upload Audio\", show_label=True, optional=True)\n",
            "/home/hosungnam/Applications/miniconda3/envs/1/lib/python3.10/site-packages/gradio/utils.py:812: UserWarning: Expected 3 arguments for function <function processAudio at 0x7ab63047edd0>, received 2.\n",
            "  warnings.warn(\n",
            "/home/hosungnam/Applications/miniconda3/envs/1/lib/python3.10/site-packages/gradio/utils.py:816: UserWarning: Expected at least 3 arguments for function <function processAudio at 0x7ab63047edd0>, received 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on local URL:  http://127.0.0.1:7865\n",
            "IMPORTANT: You are using gradio version 3.50.2, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://0391bc4132c65f428e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0391bc4132c65f428e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/hosungnam/Applications/miniconda3/envs/1/lib/python3.10/site-packages/gradio/processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "/home/hosungnam/Applications/miniconda3/envs/1/lib/python3.10/site-packages/gradio/helpers.py:784: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 안녕하세요. 잘 다니는지 한번 볼까요?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/hosungnam/Applications/miniconda3/envs/1/lib/python3.10/site-packages/gradio/processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "/home/hosungnam/Applications/miniconda3/envs/1/lib/python3.10/site-packages/gradio/helpers.py:784: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 아니 그게 얼마나 잘 되는지 내가 어떻게 알아 잘 되는지 한번 봅시다.\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7865 <> https://0391bc4132c65f428e.gradio.live\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}