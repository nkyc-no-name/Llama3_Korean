{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwbS5rSeLSRQ",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Kill gpu jobs ===========\n",
        "pids=$(nvidia-smi --query-compute-apps=pid --format=csv,noheader,nounits)\n",
        "for pid in $pids; do\n",
        "    sudo kill -9 $pid\n",
        "done\n",
        "# Log ===========\n",
        "nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "%pip uninstall -y unsloth xformers trl peft accelerate bitsandbytes datasets transformers gradio ipdb torch wandb\n",
        "%pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "%pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "%pip install torch==2.3.0 gradio ipdb wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "8f72da6f-1561-47d5-a3fc-64b9383e1d00"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# pip uninstall -y unsloth xformers trl peft accelerate bitsandbytes datasets transformers gradio ipdb torch wandb\n",
        "# pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "# pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "# pip install torch==2.3.0 gradio ipdb wandb\n",
        "\n",
        "# * | // MARK: import =====================================\n",
        "from datasets import load_dataset\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "from threading import Thread\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TextIteratorStreamer\n",
        "from transformers import TrainingArguments\n",
        "from trl import DataCollatorForCompletionOnlyLM\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "import gradio as gr\n",
        "import ipdb as pdb\n",
        "import torch\n",
        "import wandb\n",
        "\n",
        "# * | // MARK: config =====================================\n",
        "# unsloth supports RoPE (Rotary Position Embeddings), which scales internally\n",
        "MAX_SEQ_LENGTH = 4096\n",
        "COMPUTE_DTYPE = (\n",
        "    torch.bfloat16\n",
        ")  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+, A6000 is Ampere architecture.\n",
        "MODEL_DTYPE_4BIT = True\n",
        "# 4bit pre quantized models from unsloth (low network traffic, and no need to do the quantization before training the lora).\n",
        "MODELS_4BIT = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\",\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3-mini-4k-instruct\",\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",\n",
        "]\n",
        "HF_TOKEN = \"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\"\n",
        "TRAIN_PER_DEVICE_TRAIN_BATCH_SIZE = 4\n",
        "TRAIN_PER_DEVICE_EVAL_BATCH_SIZE = 1\n",
        "TRAIN_EVALUATION_STRATEGY = \"steps\"\n",
        "TRAIN_EVAL_STEPS = 0.1\n",
        "TRAIN_GRADIENT_ACCUMULATION_STEPS = 4\n",
        "TRAIN_WARMUP_RATIO = 0.2\n",
        "TRAIN_NUM_TRAIN_EPOCHS = 8\n",
        "TRAIN_LEARNING_RATE = 1e-4\n",
        "TRAIN_FP16 = not is_bfloat16_supported()\n",
        "TRAIN_BF16 = is_bfloat16_supported()\n",
        "TRAIN_LOGGING_STEPS = 10\n",
        "TRAIN_OPTIM = \"adamw_8bit\"\n",
        "TRAIN_WEIGHT_DECAY = 0.01\n",
        "TRAIN_LR_SCHEDULER_TYPE = \"warmup_stable_decay\"\n",
        "# /home/kwb425/Applications/miniconda3/envs/1/lib/python3.9/site-packages/transformers/optimization.py:410\n",
        "TRAIN_LR_SCHEDULER_KWARGS = {\"num_stable_steps\": 30, \"num_decay_steps\": 60, \"min_lr_ratio\": 1e-5, \"num_cycles\": 0.5}\n",
        "TRAIN_SEED = 3407\n",
        "TRAIN_OUTPUT_DIR = \"output\"\n",
        "\n",
        "# * | // MARK: load model =====================================\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    dtype=COMPUTE_DTYPE,\n",
        "    load_in_4bit=MODEL_DTYPE_4BIT,\n",
        "    # token = HF_TOKEN # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")\n",
        "\n",
        "# * | // MARK: lora =====================================\n",
        "# peft, updating 1 to 10% of all parameters\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # rank, 8, 16, 32, 64, 128\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,  # Supports any, but = 0 is optimized\n",
        "    bias=\"none\",  # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n",
        "    random_state=3407,\n",
        "    use_rslora=False,  # Supports rank stabilized LoRA\n",
        "    loftq_config=None,  # Supports LoftQ\n",
        ")\n",
        "\n",
        "\n",
        "# * | // MARK: data prep =====================================\n",
        "\"\"\" \n",
        "1. unsloth relies on ShareGPT style \n",
        "    when data is in this form\n",
        "        `[{\"from\": \"human\", \"value\" : \"Hi\"}, {\"from\": \"gpt\", \"value\" : \"Hi\"}]`\n",
        "            we need mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"human\", \"assistant\": \"gpt\"}\n",
        "    when data is in this form\n",
        "        `[{\"role\": \"user\", \"content\" : \"Hi\"}, {\"role\": \"assistant\", \"content\" : \"Hi\"}]`\n",
        "            we need no mapping\n",
        "2. after the optional mapper applied, we use `get_chat_template` to convert it to `llama-3 style`\n",
        "    ```\n",
        "    <|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "    Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "    Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    I'm great thanks!<|eot_id|>\n",
        "    ```\n",
        "    * note that there is no closing tag for <|begin_of_text|>\n",
        "\"\"\"\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3\",  # zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n",
        "    # mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"human\", \"assistant\": \"gpt\"},\n",
        ")\n",
        "\n",
        "\n",
        "def formatting_prompts_func(whole_dataset):\n",
        "    conversations = whole_dataset[\"conversations\"]\n",
        "    # `texts` is now in `llama-3 style`\n",
        "    texts = [\n",
        "        tokenizer.apply_chat_template(\n",
        "            conversation, tokenize=False, add_generation_prompt=False\n",
        "        )\n",
        "        for conversation in conversations\n",
        "    ]\n",
        "    return {\n",
        "        \"text\": texts,\n",
        "    }\n",
        "\n",
        "\n",
        "dataset = load_dataset(\"NoNameFactory/synth600\", split=\"train\")\n",
        "dataset = dataset.map(\n",
        "    formatting_prompts_func,\n",
        "    batched=True,\n",
        "    batch_size=1,\n",
        ")\n",
        "# dataset = dataset.select(range(N))\n",
        "dataset = dataset.train_test_split(test_size=0.05)\n",
        "\n",
        "# * | // MARK: collator (masking) =====================================\n",
        "# To train only on completions (ignoring the user's input) read TRL's docs (https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n",
        "response_template = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "instruction_template = \"<|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
        "collator = DataCollatorForCompletionOnlyLM(\n",
        "    instruction_template=instruction_template,\n",
        "    response_template=response_template,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "\n",
        "# * | // MARK: train =====================================\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,  # Can make training 5x faster for short sequences.\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=TRAIN_PER_DEVICE_TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size=TRAIN_PER_DEVICE_EVAL_BATCH_SIZE,\n",
        "        evaluation_strategy=TRAIN_EVALUATION_STRATEGY,\n",
        "        eval_steps=TRAIN_EVAL_STEPS,\n",
        "        gradient_accumulation_steps=TRAIN_GRADIENT_ACCUMULATION_STEPS,\n",
        "        warmup_ratio=TRAIN_WARMUP_RATIO,\n",
        "        num_train_epochs=TRAIN_NUM_TRAIN_EPOCHS,\n",
        "        learning_rate=TRAIN_LEARNING_RATE,\n",
        "        fp16=TRAIN_FP16,\n",
        "        bf16=TRAIN_BF16,\n",
        "        logging_steps=TRAIN_LOGGING_STEPS,\n",
        "        optim=TRAIN_OPTIM,\n",
        "        weight_decay=TRAIN_WEIGHT_DECAY,\n",
        "        lr_scheduler_type=TRAIN_LR_SCHEDULER_TYPE,\n",
        "        lr_scheduler_kwargs=TRAIN_LR_SCHEDULER_KWARGS,\n",
        "        seed=TRAIN_SEED,\n",
        "        output_dir=TRAIN_OUTPUT_DIR,\n",
        "    ),\n",
        "    data_collator=collator,\n",
        ")\n",
        "\n",
        "# * | // MARK: logging =====================================\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved, training starting...\")\n",
        "trainer_stats = trainer.train()  # Training fire away!\n",
        "wandb.finish()\n",
        "print(f\"finish training! gathering stats...\")\n",
        "model.config.use_cache = True\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")\n",
        "\n",
        "# * | // MARK: save & load =====================================\n",
        "# * Merge to 16bit, for later used with UNSLOTH or HUGGINGFACE\n",
        "# model.save_pretrained_merged(\n",
        "#     \"model\",\n",
        "#     tokenizer,\n",
        "#     save_method=\"merged_16bit\",\n",
        "# )\n",
        "# model.push_to_hub_merged(\n",
        "#     \"hf/model\",\n",
        "#     tokenizer,\n",
        "#     save_method=\"merged_16bit\",\n",
        "#     token=HF_TOKEN,\n",
        "# )\n",
        "# * Save to 8bit q8_0, for later used with GGUF (c/c++, https://github.com/ggerganov/llama.cpp)\n",
        "# * `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "# model.save_pretrained_gguf(\n",
        "#     \"model\",\n",
        "#     tokenizer,\n",
        "# )\n",
        "# model.push_to_hub_gguf(\"hf/model\", tokenizer, token=HF_TOKEN)\n",
        "# * Merge to 4bit, for later used with UNSLOTH or HUGGINGFACE\n",
        "# model.save_pretrained_merged(\n",
        "#     \"model\",\n",
        "#     tokenizer,\n",
        "#     save_method=\"merged_4bit\",\n",
        "# )\n",
        "# model.push_to_hub_merged(\n",
        "#     \"hf/model\",\n",
        "#     tokenizer,\n",
        "#     save_method=\"merged_4bit\",\n",
        "#     token=HF_TOKEN,\n",
        "# )\n",
        "# * Save to 16bit, for later used with GGUF (c/c++, https://github.com/ggerganov/llama.cpp)\n",
        "# model.save_pretrained_gguf(\"model\", tokenizer, quantization_method=\"f16\")\n",
        "# model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method=\"f16\", token=HF_TOKEN)\n",
        "# * Just LoRA adapters, for later used with UNSLOTH or HUGGINGFACE\n",
        "# model.save_pretrained_merged(\n",
        "#     \"model\",\n",
        "#     tokenizer,\n",
        "#     save_method=\"lora\",\n",
        "# )\n",
        "# model.push_to_hub_merged(\n",
        "#     \"hf/model\",\n",
        "#     tokenizer,\n",
        "#     save_method=\"lora\",\n",
        "#     token=HF_TOKEN,\n",
        "# )\n",
        "# * Save to q4_k_m, for later used with GGUF (c/c++, https://github.com/ggerganov/llama.cpp)\n",
        "# * `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "# model.save_pretrained_gguf(\"model\", tokenizer, quantization_method=\"q4_k_m\")\n",
        "# model.push_to_hub_gguf(\n",
        "#     \"hf/model\", tokenizer, quantization_method=\"q4_k_m\", token=HF_TOKEN\n",
        "# )\n",
        "# * Saving only lora (using unsloth class)\n",
        "model.push_to_hub(\n",
        "    \"NoNameFactory/llama-3.1-8b-it-4bit-synth600\",\n",
        "    token=HF_TOKEN,\n",
        ")\n",
        "# * Loading only lora (using unsloth class)\n",
        "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "#     model_name=\"NoNameFactory/llama-3.1-8b-it-4bit-synth600\",  # Lora\n",
        "#     max_seq_length=MAX_SEQ_LENGTH,\n",
        "#     dtype=COMPUTE_DTYPE,\n",
        "#     load_in_4bit=MODEL_DTYPE_4BIT,\n",
        "# )\n",
        "# * Loading only lora (using huggingface class)\n",
        "# model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "#     \"NoNameFactory/llama-3.1-8b-it-4bit-synth600\",  # Lora\n",
        "#     load_in_4bit=MODEL_DTYPE_4BIT,\n",
        "# )\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\n",
        "#     \"NoNameFactory/llama-3.1-8b-it-4bit-synth600\"\n",
        "# )\n",
        "\n",
        "# * | // MARK: inference =====================================\n",
        "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
        "# we will use `from` `value` style, so mapping comes in as dict.\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3\",  # zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n",
        "    mapping={\"role\": \"from\", \"content\": \"value\", \"user\": \"human\", \"assistant\": \"gpt\"},\n",
        ")\n",
        "\n",
        "\n",
        "def predict(message, history):\n",
        "    history_transformer_format = history + [[message, \"\"]]\n",
        "    messages = [\n",
        "        {\n",
        "            \"from\": \"system\",\n",
        "            \"value\": \"You are a helpful AI assistant. Please follow the user's request kindly.\",\n",
        "        }\n",
        "    ]\n",
        "    messages += [\n",
        "        {\"from\": \"human\", \"value\": item[0]} for item in history_transformer_format\n",
        "    ]\n",
        "    messages += [\n",
        "        {\"from\": \"gpt\", \"value\": item[1]} for item in history_transformer_format\n",
        "    ]\n",
        "    messages[-1][\"value\"] = \"\"\n",
        "    # Prepare model inputs\n",
        "    model_inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Must add for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    print(f\"message: ${message}\")\n",
        "    print(f\"history: ${history}\")\n",
        "    print(f\"model_inputs: ${model_inputs}\")\n",
        "    # Initialize the text streamer\n",
        "    text_streamer = TextIteratorStreamer(\n",
        "        tokenizer, timeout=10.0, skip_prompt=True, skip_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # Set up generation arguments\n",
        "    generate_kwargs = dict(\n",
        "        input_ids=model_inputs,\n",
        "        streamer=text_streamer,\n",
        "        max_new_tokens=10000,\n",
        "        use_cache=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    # offloading to GPU, if CPU is used, then this will suffer from GIL\n",
        "    t = Thread(target=model.generate, kwargs=generate_kwargs)\n",
        "    t.start()\n",
        "\n",
        "    # cpu streamer, this will wait until gpu thread emits each chunk\n",
        "    partial_message = \"\"\n",
        "    for new_token in text_streamer:\n",
        "        if new_token != \"<\":\n",
        "            partial_message += new_token\n",
        "            yield partial_message\n",
        "\n",
        "\n",
        "gr.ChatInterface(predict).launch(share=True, debug=True)\n",
        "\n",
        "\n",
        "# * | // MARK: bak, unsloth template =====================================\n",
        "# unsloth_template = \\\n",
        "#     \"{{ bos_token }}\"\\\n",
        "#     \"{{ 'You are a helpful assistant to the user\\n' }}\"\\\n",
        "#     \"{% for message in messages %}\"\\\n",
        "#         \"{% if message['role'] == 'user' %}\"\\\n",
        "#             \"{{ '>>> User: ' + message['content'] + '\\n' }}\"\\\n",
        "#         \"{% elif message['role'] == 'assistant' %}\"\\\n",
        "#             \"{{ '>>> Assistant: ' + message['content'] + eos_token + '\\n' }}\"\\\n",
        "#         \"{% endif %}\"\\\n",
        "#     \"{% endfor %}\"\\\n",
        "#     \"{% if add_generation_prompt %}\"\\\n",
        "#         \"{{ '>>> Assistant: ' }}\"\\\n",
        "#     \"{% endif %}\"\n",
        "# unsloth_eos_token = \"eos_token\"\n",
        "# tokenizer = get_chat_template(\n",
        "#     tokenizer,\n",
        "#     chat_template = (unsloth_template, unsloth_eos_token,), # You must provide a template and EOS token\n",
        "#     map_eos_token = True, # Maps <|im_end|> to </s> instead\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0951748aa47f4b4e8c43f11ad0b886e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1053e879eb684233ac24bc3277025aa1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1577317ccc3944ff91dad6b122673da5",
            "value": 1
          }
        },
        "0c461b195e9e4a9680429ced0a1d5910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52448b5572e748d98546cb029b664a58",
              "IPY_MODEL_e476731a964c417a830067abe34b47d0",
              "IPY_MODEL_5be7e1b546a641aea8e01cd7a0d1e959"
            ],
            "layout": "IPY_MODEL_bcc0c476d3f5489da0e4f4046988bdce"
          }
        },
        "1053e879eb684233ac24bc3277025aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d1218994c04247ac1233109bbb34be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1577317ccc3944ff91dad6b122673da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "226f0e99d75d4a16b48b9c19e1e94fed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb6deeaaadf4b1f9e4a16f8f02b15b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f2efd43520b4408adbdbd8c5a8c25e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "306ea32e4bdc4323a98263b65fd9d973": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3383ec4a58a04594b6d89f804a3edbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ac76891dfb4e49a672ac3fc6839c25",
            "placeholder": "​",
            "style": "IPY_MODEL_2f2efd43520b4408adbdbd8c5a8c25e9",
            "value": " 612/612 [00:00&lt;00:00, 221kB/s]"
          }
        },
        "375a7cbed2f942a5a2c4af2a24524368": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460ba04cdc2e4f3c9e546293ac7ddf98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0039caf33c14910ab068fb89bb9582e",
            "placeholder": "​",
            "style": "IPY_MODEL_c42a611112da4d4d8edc77190d398ced",
            "value": "README.md: 100%"
          }
        },
        "46bb87549d974eca8d7ec621be84729e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13d1218994c04247ac1233109bbb34be",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bb6deeaaadf4b1f9e4a16f8f02b15b3",
            "value": 612
          }
        },
        "4983324e1ded46f2bfb986ea9e0ae431": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a17052bdd894b1d9f44688347bda270": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5153460e9ad642d2b07f79071ea6b76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b195dd095b634c60b80ecbe92f83811a",
              "IPY_MODEL_0951748aa47f4b4e8c43f11ad0b886e0"
            ],
            "layout": "IPY_MODEL_54d6a8f16a9d42c9a3ae7612b1523e9e"
          }
        },
        "52448b5572e748d98546cb029b664a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4983324e1ded46f2bfb986ea9e0ae431",
            "placeholder": "​",
            "style": "IPY_MODEL_4a17052bdd894b1d9f44688347bda270",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "54d6a8f16a9d42c9a3ae7612b1523e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be7e1b546a641aea8e01cd7a0d1e959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375a7cbed2f942a5a2c4af2a24524368",
            "placeholder": "​",
            "style": "IPY_MODEL_306ea32e4bdc4323a98263b65fd9d973",
            "value": " 168M/168M [00:18&lt;00:00, 9.84MB/s]"
          }
        },
        "77ac76891dfb4e49a672ac3fc6839c25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a8ff21c04474c9bacbd6e85598d8e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_460ba04cdc2e4f3c9e546293ac7ddf98",
              "IPY_MODEL_46bb87549d974eca8d7ec621be84729e",
              "IPY_MODEL_3383ec4a58a04594b6d89f804a3edbe1"
            ],
            "layout": "IPY_MODEL_c68c784950c64cb8a0961d9c93c97efb"
          }
        },
        "b195dd095b634c60b80ecbe92f83811a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_226f0e99d75d4a16b48b9c19e1e94fed",
            "placeholder": "​",
            "style": "IPY_MODEL_bffd3a790cf6470c965fcc1b882a4356",
            "value": "0.052 MB of 0.052 MB uploaded\r"
          }
        },
        "bcc0c476d3f5489da0e4f4046988bdce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bffd3a790cf6470c965fcc1b882a4356": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0039caf33c14910ab068fb89bb9582e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42a611112da4d4d8edc77190d398ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c68c784950c64cb8a0961d9c93c97efb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb4c866ebec441d9a891b2ab8a0bdd65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e476731a964c417a830067abe34b47d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdd0941756084dfaab5c1abf9cd4fcbc",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb4c866ebec441d9a891b2ab8a0bdd65",
            "value": 167832240
          }
        },
        "fdd0941756084dfaab5c1abf9cd4fcbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
